{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Reestimating Preference Parameters Using Experimental Data\n",
    "\n",
    "This notebook allows you to reestimate preference parameters using the full experimental data for each subject.\n",
    "\n",
    "You can use the original prior distribution and likelihood specification, or you can specify a new prior or choice model that you would like to estimate.\n",
    "\n",
    "Begin by importing the required packages and BACE functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "import os, sys, importlib\n",
    "from pathlib import Path\n",
    "\n",
    "def import_parents(level=1):\n",
    "    global __package__\n",
    "    file = Path(os.path.abspath('')).resolve()\n",
    "    parent, top = file.parent, file.parents[level - 1]\n",
    "\n",
    "    sys.path.append(str(top))\n",
    "    try:\n",
    "        sys.path.remove(str(parent))\n",
    "    except ValueError: # already removed\n",
    "        pass\n",
    "\n",
    "    __package__ = '.'.join(parent.parts[len(top.parts):])\n",
    "    importlib.import_module(__package__) # won't be needed after that\n",
    "\n",
    "import_parents(level=2)\n",
    "\n",
    "# Import database connection and pmc function\n",
    "from app.database.db import table, decimal_to_float\n",
    "from app.bace.pmc_inference import pmc\n",
    "from app.bace.user_config import answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reestimate preference parameters using the existing BACE specifications, you can run the following line:\n",
    "\n",
    "```\n",
    "from bace.user_config import theta_params, likelihood_pdf, size_thetas\n",
    "```\n",
    "\n",
    "Alternatively, you can specify each of the following parameters using the same process that you used to define the components in `app/bace/user_config.py`:\n",
    "- `theta_params`: Specifies the prior distribution.\n",
    "- `likelihood_pdf`: Specify the likelihood of observing each answer in answers.\n",
    "- `size_thetas`: The size of the sample drawn from `theta_params`. Since speed is less important outside of an experiment, you can improve the precision of estimates by increasing this number.\n",
    "\n",
    "Note that the choice model defined in `likelihood_pdf` can depend on new preference parameters in `theta_params` or combinations of the original design components that an individual saw.\n",
    "\n",
    "In this example, we will use the existing BACE specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.bace.user_config import theta_params, likelihood_pdf, size_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, specify `estimation_version` with notes that you want to record in the output file, and specify `output_file` with the path that you want to use to save your `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output file path.\n",
    "output_file = \"allpriors.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to clean the design and answer histories for each individual in the database.\n",
    "\n",
    "It ensures that the design and answer histories are the same length for re-estimation; these can differ if, for example, an individual exited the survey early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_designs_and_answers(item, answers):\n",
    "\n",
    "    str_answers = [str(answer) for answer in answers]\n",
    "\n",
    "    design_hist = item['design_history'].copy()\n",
    "    answer_hist = item['answer_history'].copy()\n",
    "    answer_hist.extend([None] * (len(design_hist) - len(answer_hist)))\n",
    "\n",
    "    # Store Output\n",
    "    design_history = []\n",
    "    answer_history = []\n",
    "\n",
    "\n",
    "    for design, answer in zip(design_hist, answer_hist):\n",
    "\n",
    "        if (design is not None) and (answer is not None) and (str(answer) in str_answers):\n",
    "\n",
    "            design_history.append(design)\n",
    "            answer_history.append(answer)\n",
    "\n",
    "    return design_history, answer_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code queries your database for all items. Each item contains all information for an individual survey respondent, which is characterized by a unique `profile_id`.\n",
    "\n",
    "Note: You can also modify the code to get the data from a csv file after using `/data/save_data.py` instead of querying from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import openpyxl\n",
    "import csv\n",
    "\n",
    "id_column = 'profile_id' # Unique ID column for each profile\n",
    "table_name = 'bace-db' # Update this if the name of the database TableName in template.yaml is changed\n",
    "# Update `table_region` below to the region created with `sam deploy --guided`, saved in the SAM configuration file (samconfig.toml by default)\n",
    "#   if different from the default region in ~/.aws/config (or C:\\Users\\USERNAME\\.aws\\config)\n",
    "table_region = boto3.Session().region_name # example if different from default: table_region = 'us-east-2'\n",
    "# os.environ['AWS_PROFILE'] = \"YOUR_AWS_PROFILE_NAME\" # Set this if your current AWS login profile is not the default one -- see profiles in ~/.aws/config (or C:\\Users\\USERNAME\\.aws\\config)\n",
    "\n",
    "############################\n",
    "\n",
    "# Start database connection\n",
    "ddb = boto3.resource('dynamodb', region_name = table_region)\n",
    "table = ddb.Table(table_name)\n",
    "\n",
    "# Scan all data from DynamoDB table\n",
    "response = table.scan()\n",
    "db_items = response['Items']\n",
    "\n",
    "with open('profiles_to_test.csv', 'r', encoding='utf-8-sig') as file:\n",
    "    reader = csv.reader(file, delimiter='\\n')\n",
    "    profiles_to_test = [row[0] for row in reader]\n",
    "\n",
    "# Go beyond the 1mb limit: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html\n",
    "while 'LastEvaluatedKey' in response:\n",
    "    response = table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])\n",
    "    db_items.extend(response['Items'])\n",
    "\n",
    "db_items = [item for item in db_items if item['profile_id'] in profiles_to_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.stats\n",
    "# output = []\n",
    "\n",
    "# for item in db_items:\n",
    "\n",
    "#     # Conver DynamoDB Decimal type to floats\n",
    "#     item = decimal_to_float(item)\n",
    "\n",
    "#     # Get cleaned design and answer histories.\n",
    "#     design_history, answer_history = clean_designs_and_answers(item, answers)\n",
    "#     ND = len(design_history)\n",
    "\n",
    "#     # Estimate preferences if the individual answered at least one question.\n",
    "#     if ND > 0:\n",
    "\n",
    "#         try:\n",
    "\n",
    "#             #################################################################################\n",
    "#             ### Edit this block to update the method for calculating posterior estimates. ###\n",
    "#             #################################################################################\n",
    "\n",
    "#             theta_params = dict(\n",
    "#                 WTP_1 = scipy.stats.uniform(0.02,0.18),\n",
    "#                 WTP_2 = scipy.stats.uniform(0.02,0.18),\n",
    "#                 p = scipy.stats.uniform()\n",
    "#             )\n",
    "\n",
    "#             # Compute posterior estimates using Population Monte Carlo\n",
    "#             posterior_thetas_original = pmc(\n",
    "#                 theta_params,\n",
    "#                 answer_history,\n",
    "#                 design_history,\n",
    "#                 likelihood_pdf,\n",
    "#                 size_thetas\n",
    "#             )\n",
    "\n",
    "#             theta_params = dict(\n",
    "#                 WTP_1 = scipy.stats.uniform(0.02,0.36),\n",
    "#                 WTP_2 = scipy.stats.uniform(0.02,0.36),\n",
    "#                 p = scipy.stats.uniform()\n",
    "#             )\n",
    "\n",
    "#             # Compute posterior estimates using Population Monte Carlo\n",
    "#             posterior_thetas_weak= pmc(\n",
    "#                 theta_params,\n",
    "#                 answer_history,\n",
    "#                 design_history,\n",
    "#                 likelihood_pdf,\n",
    "#                 size_thetas\n",
    "#             )\n",
    "\n",
    "#             theta_params = dict(\n",
    "#                 WTP_1 = scipy.stats.uniform(0.02,0.09),\n",
    "#                 WTP_2 = scipy.stats.uniform(0.02,0.09),\n",
    "#                 p = scipy.stats.uniform()\n",
    "#             )\n",
    "\n",
    "#             # Compute posterior estimates using Population Monte Carlo\n",
    "#             posterior_thetas_strong= pmc(\n",
    "#                 theta_params,\n",
    "#                 answer_history,\n",
    "#                 design_history,\n",
    "#                 likelihood_pdf,\n",
    "#                 size_thetas\n",
    "#             )\n",
    "\n",
    "#             theta_params = dict(\n",
    "#                 WTP_1 = scipy.stats.uniform(),\n",
    "#                 WTP_2 = scipy.stats.uniform(),\n",
    "#                 p = scipy.stats.uniform()\n",
    "#             )\n",
    "\n",
    "#             # Compute posterior estimates using Population Monte Carlo\n",
    "#             posterior_thetas_uninformative= pmc(\n",
    "#                 theta_params,\n",
    "#                 answer_history,\n",
    "#                 design_history,\n",
    "#                 likelihood_pdf,\n",
    "#                 size_thetas\n",
    "#             )\n",
    "\n",
    "#             # Calculate the mean and median posterior estimate for each parameter.\n",
    "#             # Update this code to store alternative statistics.\n",
    "#             estimates_original = posterior_thetas_original.agg(['mean', 'median']).to_dict()\n",
    "#             estimates_weak = posterior_thetas_weak.agg(['mean', 'median']).to_dict()\n",
    "#             estimates_strong = posterior_thetas_strong.agg(['mean', 'median']).to_dict()\n",
    "#             estimates_uninformative = posterior_thetas_uninformative.agg(['mean', 'median']).to_dict()\n",
    "\n",
    "#             estimates_original = {\"orignal_\" + key: value for key, value in estimates_original.items()}\n",
    "#             estimates_weak = {\"weak_\" + key: value for key, value in estimates_weak.items()}\n",
    "#             estimates_strong = {\"strong_\" + key: value for key, value in estimates_strong.items()}\n",
    "#             estimates_uninformative = {\"uninformative_\" + key: value for key, value in estimates_uninformative.items()}\n",
    "\n",
    "\n",
    "#             #############################################################################\n",
    "#             #############################################################################\n",
    "\n",
    "#             reestimation_successful = 1\n",
    "\n",
    "\n",
    "#         except:\n",
    "\n",
    "#             # What do you want to happen if the re-estimation triggers an error?\n",
    "#             reestimation_successful = 0\n",
    "#             estimates_original = {}\n",
    "#             estimates_weak = {}\n",
    "#             estimates_strong = {}\n",
    "#             estimates_uninformative = {}\n",
    "\n",
    "#         # Store output.\n",
    "#         # You can add additional variables associated with an item using item.get('var') to the exported csv.\n",
    "#         individual_output = {\n",
    "#             \"profile_id\": item.get(\"profile_id\"),\n",
    "#             \"n_designs\": ND,\n",
    "#             \"param_1\": item.get(\"param_1\"),\n",
    "#             \"param_2\": item.get(\"param_2\"),\n",
    "#             \"reestimation_successful\": reestimation_successful,\n",
    "#             **estimates_original,\n",
    "#             **estimates_weak,\n",
    "#             **estimates_strong,\n",
    "#             **estimates_uninformative\n",
    "#         }\n",
    "\n",
    "#         output.append(individual_output)\n",
    "\n",
    "\n",
    "# # Convert output to dataframe and write to .csv\n",
    "# output_df = pd.json_normalize(output)\n",
    "# output_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "output = []\n",
    "\n",
    "for item in db_items:\n",
    "\n",
    "    # Conver DynamoDB Decimal type to floats\n",
    "    item = decimal_to_float(item)\n",
    "\n",
    "    # Get cleaned design and answer histories.\n",
    "    design_history, answer_history = clean_designs_and_answers(item, answers)\n",
    "    ND = len(design_history)\n",
    "\n",
    "    # Estimate preferences if the individual answered at least one question.\n",
    "    if ND > 0:\n",
    "\n",
    "        # try:\n",
    "\n",
    "            #################################################################################\n",
    "            ### Edit this block to update the method for calculating posterior estimates. ###\n",
    "            #################################################################################\n",
    "\n",
    "# Assuming pmc, answer_history, design_history, likelihood_pdf, size_thetas are already defined\n",
    "\n",
    "        def compute_posterior_estimates(i):\n",
    "            upper = float(i) / 10.0\n",
    "            theta_params = dict(\n",
    "                WTP_1=scipy.stats.uniform(0, upper),\n",
    "                WTP_2=scipy.stats.uniform(0, upper),\n",
    "                p=scipy.stats.uniform()\n",
    "            )\n",
    "\n",
    "            # Compute posterior estimates using Population Monte Carlo\n",
    "            posterior_thetas = pmc(\n",
    "                theta_params,\n",
    "                answer_history,\n",
    "                design_history,\n",
    "                likelihood_pdf,\n",
    "                size_thetas\n",
    "            )\n",
    "\n",
    "            # Calculate the mean and median posterior estimate for each parameter.\n",
    "            estimates = posterior_thetas.agg(['mean', 'median', 'std']).to_dict()\n",
    "            estimates = {str(i) + '_' + key: value for key, value in estimates.items()}\n",
    "            return estimates\n",
    "\n",
    "        # Set a consistent random seed\n",
    "        np.random.seed(42)\n",
    "\n",
    "        out = {}\n",
    "        for i in range(1, 11):\n",
    "            estimates = compute_posterior_estimates(i)\n",
    "            out.update(estimates)\n",
    "\n",
    "                # Store output.\n",
    "        # You can add additional variables associated with an item using item.get('var') to the exported csv.\n",
    "        individual_output = {\n",
    "            \"profile_id\": item.get(\"profile_id\"),\n",
    "            \"n_designs\": ND,\n",
    "            \"param_1\": item.get(\"param_1\"),\n",
    "            \"param_2\": item.get(\"param_2\"),\n",
    "            **out,\n",
    "        }\n",
    "\n",
    "        output.append(individual_output)\n",
    "\n",
    "\n",
    "# Convert output to dataframe and write to .csv\n",
    "output_df = pd.json_normalize(output)\n",
    "output_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can update this code block above to adjust other components of the reestimation.\n",
    "\n",
    "For example, the notebook defaults to using Population Monte Carlo to reestimate preferences.\n",
    "\n",
    "If you want to estimate preferences using an alternative method, you can update the following block. For example, you could perform logistic regression using each individual's data or you can use an alternative method to perform Bayesian Inference.\n",
    "\n",
    "You can also edit what statistics are saved when forming estimates.\n",
    "\n",
    "```python\n",
    "#############################################################################\n",
    "### Edit this block to update the method for calculating posterior estimates.\n",
    "#############################################################################\n",
    "\n",
    "# Compute posterior estimates using Population Monte Carlo\n",
    "posterior_thetas = pmc(\n",
    "    theta_params, \n",
    "    answer_history, \n",
    "    design_history, \n",
    "    likelihood_pdf, \n",
    "    size_thetas\n",
    ")\n",
    "\n",
    "# Calculate the mean and median posterior estimate for each parameter.\n",
    "# Update this code to store alternative statistics.\n",
    "estimates = posterior_thetas.agg(['mean', 'median']).to_dict()\n",
    "\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "```\n",
    "\n",
    "We hope this notebook is useful for recomputing preference estimates after an experiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
